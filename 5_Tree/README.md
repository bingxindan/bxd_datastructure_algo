> 树、二叉树
>
> 二叉查找树
>
> 平衡二叉查找树、红黑树
>
> 递归树

# 树（Tree）

*   N(N>=0)个节点的有限集

    *   在树为有根树的情况下,有且仅有一个特定的称为根结点
    *   当N>1时，其余结点可分为若干个互不相交的有限集，其中每个集合也可以看作一颗树，称之为根的子树
*   每个元素我们叫做“节点”；
*   用来连接相邻节点之间的关系，我们叫做“父子关系”。
*   父节点是同一个节点，它们之间互称为兄弟节点。
*   没有父节点的节点叫做根节点。没有子节点的节点叫做叶子节点或者叶节点
*   高度（Height）

    *   节点的高度：节点到叶子节点的最长路径（边数）
    *   节点深度：根节点到这个节点所经历的边的数
    *   节点的层数：节点的深度+1
    *   树的高度：根节点的高度
    *   树这种数据结构的高度也是一样，从最底层开始计数，并且计数的起点是 0。
*   深度（Depth）

    *   树这种数据结构的深度也是类似的，从根结点开始度量，并且计数起点也是 0。
*   层（Level）

# 二叉树（Binary Tree）

*   每个节点最多有两个“叉”，也就是两个子节点，分别是左子节点和右子节点。
*   二叉树并不要求每个节点都有两个子节点，有的节点只有左子节点，有的节点只有右子节点。
*   **满二叉树**

    *   二叉树中，叶子节点全都在最底层，除了叶子节点之外，每个节点都有左右两个子节点，这种二叉树就叫做满二叉树。
*   完全二叉树

    *   叶子节点都在最底下两层，最后一层的叶子节点都靠左排列，并且除了最后一层，其他层的节点个数都要达到最大，这种二叉树叫做完全二叉树。

# 存储二叉树

*   两种方法，一种是基于指针或者引用的二叉链式存储法，一种是基于数组的顺序存储法。
*   链式存储法

    *   每个节点有三个字段，其中一个存储数据，另外两个是指向左右子节点的指针。
    *   只要拎住根节点，就可以通过左右子节点的指针，把整棵树都串起来。
    *   大部分二叉树代码都是通过这种结构来实现的。
*   基于数组的顺序存储法

    *   我们把根节点存储在下标 i = 1 的位置，那左子节点存储在下标 2 \* i = 2 的位置，右子节点存储在 2 \* i + 1 = 3 的位置。
    *   如果某棵二叉树是一棵完全二叉树，那用数组存储无疑是最节省内存的一种方式。因为数组的存储方式并不需要像链式存储法那样，要存储额外的左右子节点的指针。
    *   这也是为什么完全二叉树会单独拎出来的原因，也是为什么完全二叉树要求最后一层的子节点都靠左的原因。
    *   堆其实就是一种完全二叉树，最常用的存储方式就是数组。

# 二叉树的遍历

*   前序遍历、中序遍历和后序遍历。
*   前、中、后序，表示的是节点与它的左右子树节点遍历打印的先后顺序。

    *   前序遍历是指，对于树中的任意节点来说，先打印这个节点，然后再打印它的左子树，最后打印它的右子树。
    *   中序遍历是指，对于树中的任意节点来说，先打印它的左子树，然后再打印它本身，最后打印它的右子树。
    *   后序遍历是指，对于树中的任意节点来说，先打印它的左子树，然后再打印它的右子树，最后打印这个节点本身。
*   二叉树的前、中、后序遍历就是一个递归的过程。比如，前序遍历，其实就是先打印根节点，然后再递归地打印左子树，最后递归地打印右子树。
*   写递归代码的关键，就是看能不能写出递推公式，而写递推公式的关键就是，如果要解决问题 A，就假设子问题 B、C 已经解决，然后再来看如何利用 B、C 来解决 A。所以，我们可以把前、中、后序遍历的递推公式都写出来。



        前序遍历的递推公式：
        preOrder(r) = print r->preOrder(r->left)->preOrder(r->right)

        中序遍历的递推公式：
        inOrder(r) = inOrder(r->left)->print r->inOrder(r->right)

        后序遍历的递推公式：
        postOrder(r) = postOrder(r->left)->postOrder(r->right)->print r



        void preOrder(Node* root) {
            if (root == null) return;
            print root // 此处为伪代码，表示打印root节点
            preOrder(root->left);
            preOrder(root->right);
        }
        
        void inOrder(Node* root) {
            if (root == null) return;
            inOrder(root->left);
            print root // 此处为伪代码，表示打印root节点
            inOrder(root->right);
        }
        
        void postOrder(Node* root) {
            if (root == null) return;
            postOrder(root->left);
            postOrder(root->right);
            print root // 此处为伪代码，表示打印root节点
        }

*   二叉树遍历的时间复杂度是 O(n)。

# 二叉查找树（Binary Search Tree）

*   二叉查找树最大的特点就是，支持动态数据集合的快速插入、删除、查找操作。
*   散列表也是支持这些操作的，并且散列表的这些操作比二叉查找树更高效，时间复杂度是 O(1)。
*   有了这么高效的散列表，使用二叉树的地方是不是都可以替换成散列表呢？有没有哪些地方是散列表做不了，必须要用二叉树来做的呢？
*
*   二叉查找树是二叉树中最常用的一种类型，也叫二叉搜索树。二叉查找树是为了实现快速查找而生的。不过，它不仅仅支持快速查找一个数据，还支持快速插入、删除一个数据。
*   它是怎么做到这些的呢？

    *   这些都依赖于二叉查找树的特殊结构。
    *   二叉查找树要求，在树中的任意一个节点，其左子树中的每个节点的值，都要小于这个节点的值，而右子树节点的值都大于这个节点的值。
*   二叉查找树的查找操作

    *   如何在二叉查找树中查找一个节点
    *   先取根节点，如果它等于我们要查找的数据，那就返回。如果要查找的数据比根节点的值小，那就在左子树中递归查找；如果要查找的数据比根节点的值大，那就在右子树中递归查找。
*   二叉查找树的插入操作

    *   二叉查找树的插入过程有点类似查找操作。
    *   新插入的数据一般都是在叶子节点上，所以我们只需要从根节点开始，依次比较要插入的数据和节点的大小关系。
*   二叉查找树的删除操作

    *   第一种情况是，如果要删除的节点没有子节点，我们只需要直接将父节点中，指向要删除节点的指针置为 null。
    *   第二种情况是，如果要删除的节点只有一个子节点（只有左子节点或者右子节点），我们只需要更新父节点中，指向要删除节点的指针，让它指向要删除节点的子节点就可以了。
    *   第三种情况是，如果要删除的节点有两个子节点，这就比较复杂了。

        *   我们需要找到这个节点的右子树中的最小节点，把它替换到要删除的节点上。
        *   然后再删除掉这个最小节点，因为最小节点肯定没有左子节点（如果有左子结点，那就不是最小节点了），所以，我们可以应用上面两条规则来删除这个最小节点。
    *   有个非常简单、取巧的方法，就是单纯将要删除的节点标记为“已删除”，但是并不真正从树中将这个节点去掉。这样原本删除的节点还需要存储在内存中，比较浪费内存空间，但是删除操作就变得简单了很多。而且，这种处理方法也并没有增加插入、查找操作代码实现的难度。
*   中序遍历二叉查找树，可以输出有序的数据序列，时间复杂度是 O(n)，非常高效。因此，二叉查找树也叫作二叉排序树。
*   如果存储的两个对象键值相同，这种情况该怎么处理呢？

    *   第一种方法比较容易。二叉查找树中每一个节点不仅会存储一个数据，因此我们通过链表和支持动态扩容的数组等数据结构，把值相同的数据都存储在同一个节点上。
    *   第二种方法比较不好理解，不过更加优雅。

        *   每个节点仍然只存储一个数据。
        *   在查找插入位置的过程中，如果碰到一个节点的值，与要插入数据的值相同，我们就将这个要插入的数据放到这个节点的右子树，也就是说，把这个新插入的数据当作大于这个节点的值来处理。
        *   当要查找数据的时候，遇到值相同的节点，我们并不停止查找操作，而是继续在右子树中查找，直到遇到叶子节点，才停止。这样就可以把键值等于要查找值的所有节点都找出来。
        *   对于删除操作，我们也需要先查找到每个要删除的节点，然后再按前面讲的删除操作的方法，依次删除。

# 二叉查找树的时间复杂度分析

*   根节点的左右子树极度不平衡，已经退化成了链表，所以查找的时间复杂度就变成了 O(n)。
*   最理想的情况，二叉查找树是一棵完全二叉树（或满二叉树）。不管操作是插入、删除还是查找，时间复杂度其实都跟树的高度成正比，也就是 O(height)。
*   既然这样，现在问题就转变成另外一个了，也就是，如何求一棵包含 n 个节点的完全二叉树的高度？

    *   树的高度就等于最大层数减一，为了方便计算，我们转换成层来表示。
    *   包含 n 个节点的完全二叉树中，第一层包含 1 个节点，第二层包含 2 个节点，第三层包含 4 个节点，依次类推，下面一层节点个数是上一层的 2 倍，第 K 层包含的节点个数就是 2^(K-1)。
    *   对于完全二叉树来说，最后一层的节点个数有点儿不遵守上面的规律了。它包含的节点个数在 1 个到 2^(L-1) 个之间（我们假设最大层数是 L）。
    *   完全二叉树的高度小于等于 log2n。
*   完全二叉树的层数小于等于 log2n +1，也就是说，完全二叉树的高度小于等于 log2n。

# 相对散列表，好像并没有什么优势，那我们为什么还要用二叉查找树呢？

*   第一，散列表中的数据是无序存储的，如果要输出有序的数据，需要先进行排序。而对于二叉查找树来说，我们只需要中序遍历，就可以在 O(n) 的时间复杂度内，输出有序的数据序列。
*   第二，散列表扩容耗时很多，而且当遇到散列冲突时，性能不稳定，尽管二叉查找树的性能不稳定，但是在工程中，我们最常用的平衡二叉查找树的性能非常稳定，时间复杂度稳定在 O(logn)。
*   第三，笼统地来说，尽管散列表的查找等操作的时间复杂度是常量级的，但因为哈希冲突的存在，这个常量不一定比 logn 小，所以实际的查找速度可能不一定比 O(logn) 快。加上哈希函数的耗时，也不一定就比平衡二叉查找树的效率高。
*   第四，散列表的构造比二叉查找树要复杂，需要考虑的东西很多。比如散列函数的设计、冲突解决办法、扩容、缩容等。平衡二叉查找树只需要考虑平衡性这一个问题，而且这个问题的解决方案比较成熟、固定。
